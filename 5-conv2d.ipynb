{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks for Jet-Images\n",
    "Author: Javier Duarte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load numpy arrays\n",
    "Here, we load the numpy arrays containing the 4D tensors of \"jet-images\" (see https://arxiv.org/pdf/1511.05190.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "h5f = h5py.File(\"data/jet_images.h5\", \"r\")\n",
    "\n",
    "jet_images_dict = {}\n",
    "jet_images_dict['QCD'] = h5f['QCD'][()]\n",
    "jet_images_dict['TT'] = h5f['TT'][()]\n",
    "\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4D tensor (tensorflow backend)\n",
    "# 1st dim is jet index\n",
    "# 2nd dim is eta bin\n",
    "# 3rd dim is phi bin\n",
    "# 4th dim is pt value (or rgb values, etc.)\n",
    "print(jet_images_dict['QCD'].shape)\n",
    "print(jet_images_dict['TT'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting jet-images\n",
    "Let's plot some jet-images (individual jets and averaged over all jets)\n",
    "\n",
    "**Question 1:**  Try to plot the average W and QCD jet-images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# plot one W jet\n",
    "i = 7\n",
    "plt.figure('W') \n",
    "plt.imshow(jet_images_dict['TT'][i,:,:,0].T, norm=mpl.colors.LogNorm(), origin='lower', interpolation='none')\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('pT')\n",
    "plt.xlabel('ieta')\n",
    "plt.ylabel('iphi')\n",
    "plt.show()\n",
    "\n",
    "# plot average W jet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot one QCD jet\n",
    "i = 7\n",
    "plt.figure() \n",
    "plt.imshow(jet_images_dict['QCD'][i,:,:,0].T, norm=mpl.colors.LogNorm(), origin='lower', interpolation='none')\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('pT')\n",
    "plt.xlabel('ieta')\n",
    "plt.ylabel('iphi')\n",
    "plt.show()\n",
    "\n",
    "# plot average QCD jet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our convolutional model\n",
    "**Question 2:** Here we have a relatively simple `Conv2D` model using regularization, batch normalization, max pooling, and a fully connected layer before the ouput. Implement the network defined in https://arxiv.org/pdf/1511.05190.pdf. Compare the performance and number of parameters when using fully connected layers instead of convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dropout, Dense, BatchNormalization, Concatenate\n",
    "from keras.regularizers import l1,l2\n",
    "nx = 30\n",
    "ny = 30\n",
    "inputs = Input(shape=(nx, ny, 1), name='input')\n",
    "x = Conv2D(8, (3, 3), \n",
    "           strides=(1, 1), \n",
    "           padding='same', \n",
    "           activation='relu', \n",
    "           name='conv2d_1', \n",
    "           kernel_regularizer=l2(0.01))(inputs)\n",
    "x = BatchNormalization(momentum=0.6, name='batchnorm_1')(x)\n",
    "x = MaxPool2D(pool_size=(2, 2), name='maxpool2d_1')(x)\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dense(64, activation='relu', name='dense')(x)\n",
    "outputs = Dense(1, activation='sigmoid', name='output')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing the data into testing and training dataset\n",
    "\n",
    "We will split the data into two parts (one for training+validation and one for testing).\n",
    "**Note:**  We will not apply \"image normalization\" preprocessing: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html.\n",
    "**Question 3:** Why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_images = np.concatenate([jet_images_dict['TT'],\n",
    "                             jet_images_dict['QCD']])\n",
    "jet_labels = np.concatenate([np.ones(len(jet_images_dict['TT'])), \n",
    "                             np.zeros(len(jet_images_dict['QCD']))])\n",
    "\n",
    "X = jet_images\n",
    "Y = jet_labels\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size=0.2, random_state=7)\n",
    "\n",
    "print 'number of W jets for training/validation: %i'%np.sum(Y_train_val==1)\n",
    "print 'number of QCD jets for training/validation: %i'%np.sum(Y_train_val==0)\n",
    "\n",
    "print 'number of W jets for testing: %i'%np.sum(Y_test==1)\n",
    "print 'number of QCD jets for testing: %i'%np.sum(Y_test==0)\n",
    "\n",
    "# early stopping callback\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# model checkpoint callback\n",
    "# this saves our model architecture + parameters into conv2d_model.h5\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "model_checkpoint = ModelCheckpoint('conv2d_model.h5', monitor='val_loss', \n",
    "                                   verbose=0, save_best_only=True, t\n",
    "                                   save_weights_only=False, mode='auto', \n",
    "                                   period=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training\n",
    "Here, we run the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier\n",
    "history = model.fit(X_train_val, Y_train_val, \n",
    "                    epochs=100, \n",
    "                    batch_size=1024, \n",
    "                    verbose=0, # switch to 1 for more verbosity\n",
    "                    callbacks=[early_stopping, model_checkpoint], \n",
    "                    validation_split=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot performance\n",
    "Here, we plot the history of the training and the performance in a ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# plot loss vs epoch\n",
    "plt.figure(figsize=(15,10))\n",
    "ax = plt.subplot(2, 2, 1)\n",
    "ax.plot(history.history['loss'], label='loss')\n",
    "ax.plot(history.history['val_loss'], label='val_loss')\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('loss')\n",
    "\n",
    "# plot accuracy vs epoch\n",
    "ax = plt.subplot(2, 2, 2)\n",
    "ax.plot(history.history['acc'], label='acc')\n",
    "ax.plot(history.history['val_acc'], label='val_acc')\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('acc')\n",
    "\n",
    "# Plot ROC\n",
    "Y_predict = model.predict(X_test)\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, Y_predict)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "ax = plt.subplot(2, 2, 3)\n",
    "ax.plot(fpr, tpr, lw=2, color='cyan', label='auc = %.3f' % (roc_auc))\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k', label='random chance')\n",
    "ax.set_xlim([0, 1.0])\n",
    "ax.set_ylim([0, 1.0])\n",
    "ax.set_xlabel('false positive rate')\n",
    "ax.set_ylabel('true positive rate')\n",
    "ax.set_title('receiver operating curve')\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-hats",
   "language": "python",
   "name": "machine-learning-hats"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}



<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Graph Neural Networks with Keras and Cora &#8212; Machine Learning HATS</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/4-gnn-cora';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Variational Autoencoders with Keras and MNIST" href="5-vae-mnist.html" />
    <link rel="prev" title="Convolutional Neural Networks for Jet-Images" href="3-conv2d.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.pdf" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/logo.pdf" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    CMS Machine Learning Hands-on Advanced Tutorial Session (HATS)
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1-datasets-uproot.html">Loading Datasets</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="2-dense.html">Dense networks</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="2.1-dense-keras.html">Dense neural network with Keras</a></li>
<li class="toctree-l2"><a class="reference internal" href="2.2-dense-pytorch.html">Dense neural network with PyTorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="2.3-dense-bayesian-optimization.html">Optimize a dense network with Bayesian optimization</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="3-conv2d.html">Convolutional Neural Networks for Jet-Images</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Graph Neural Networks with Keras and Cora</a></li>
<li class="toctree-l1"><a class="reference internal" href="5-vae-mnist.html">Variational Autoencoders with Keras and MNIST</a></li>

<li class="toctree-l1"><a class="reference internal" href="6-gan-mnist.html">Generative Adversarial Networks with Keras and MNIST</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/FNALLPC/machine-learning-hats/master?urlpath=tree/notebooks/4-gnn-cora.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/FNALLPC/machine-learning-hats/blob/master/notebooks/4-gnn-cora.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/FNALLPC/machine-learning-hats" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/FNALLPC/machine-learning-hats/issues/new?title=Issue%20on%20page%20%2Fnotebooks/4-gnn-cora.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/4-gnn-cora.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Graph Neural Networks with Keras and Cora</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#coding">Coding!</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-dataset">The Dataset</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#experiment-setup">Experiment setup</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#converting-data-to-a-graph">Converting data to a graph</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#build-the-model">Build the model!</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#train-the-model">Train the model</a></li>
</ul>
</li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="graph-neural-networks-with-keras-and-cora">
<h1>Graph Neural Networks with Keras and Cora<a class="headerlink" href="#graph-neural-networks-with-keras-and-cora" title="Permalink to this heading">#</a></h1>
<p>Author: <a class="reference external" href="https://github.com/savvy379">Savannah Thais</a></p>
<p>Adapted from the <a class="reference external" href="https://keras.io/examples/graph/gnn_citations/">Keras Tutorial</a></p>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading">#</a></h2>
<p>This notebook teaches the reader how to build a Graph Neural Network (GNN) with Keras. It is a modified version of the Keras <a class="reference external" href="https://keras.io/examples/graph/gnn_citations/">Tutorial</a> on GNNs. This setup and example was selected to work well with the existing LPC-HATS ML Tutorial tech stack, however I note that <a class="reference external" href="https://pytorch-geometric.readthedocs.io/en/latest/">Pytorch Geometric</a>(PyG) is much more commonly used to construct and train GNNs and other Geometric Deep Learning models. This notebook introduces the theory and basics of building and training a GNN, but I encourage you to explore the PyG <a class="reference external" href="https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html">tutorials</a> as well.</p>
<p>A graph <span class="math notranslate nohighlight">\(G\)</span> is a mathematical object consisting of a set of nodes (vertices) <span class="math notranslate nohighlight">\(N\)</span> and edges <span class="math notranslate nohighlight">\(E\)</span>, <span class="math notranslate nohighlight">\(G=(N,E)\)</span>. Graphs can easily represent a wide range of structured data including atoms in molecules, users in a social network, cities and roads in a transportation system, players in team sports, objects interacting in a dynamical physical system, detector events , and more. The nodes and edges of the graph can have associated features as defined by the developer; these can include geometric information (ie particle hit locations in a detector) and non-geometric information (ie particle momenta). Graphs can be directed or undirected. A major advantage of GNNs is that they can handle input data of varying sizes: each graph processed by the network can have a different number of nodes and edges, making them well suited for a range of HEP applications.</p>
<div>
<img src="attachment:image.png" width="500">
    </div>
<p>In general, GNNs work by leveraging local information across the graph structure to intelligently re-embed the edges and nodes. A commonly used class of GNNs (and the focus of this tutorial) is the Graph Convolutional Network (GCN). GCNs use the same convolution operations as in a normal CNN, but apply the convolutions to node neighborhoods rather than a fixed data tensor (like an image matrix). These are considered a type of “Message Passing Network” when are ‘message’ is constructed by combining and transforming information from neighboring nodes and that message is ‘passed’ to a target node and used to update its features. In this way the entire graph can be transformed such that each node is updated to include additional useful information. The convolved graph is typically then processed by an additional linear layer that uses node and or edge features to do classification or regression on individual graph elements, graph substructures, or the graph as a whole. (Note: the same message passing structure can be applied to edges instead of nodes to update edge features as well).</p>
<p><img alt="image.png" src="notebooks/attachment:image.png" /></p>
<p>In mathematical terms, a single graph convolution layer can be described as:</p>
<div>
<img src=attachment:image.png width=600>
    </div>
<p>Here, <span class="math notranslate nohighlight">\(h_v^0\)</span> is the initial embedding of node <span class="math notranslate nohighlight">\(v\)</span> (ie the original node features). To update the embedding of node <span class="math notranslate nohighlight">\(v\)</span>, <span class="math notranslate nohighlight">\(h_v^k\)</span>, the ‘message’ is constructed by applying a function <span class="math notranslate nohighlight">\(f\)</span> to a the average over the current embedding of all the neighboring nodes (nodes connected to <span class="math notranslate nohighlight">\(v\)</span> by a graph edge: <span class="math notranslate nohighlight">\(N(v)\)</span>) <span class="math notranslate nohighlight">\(\sum_{u \in N(v)}\frac{h_u^{k-1}}{deg(v)}\)</span> and, optionally, the current embedding of the target node: <span class="math notranslate nohighlight">\(h_v^{k-1}\)</span> then passed through a non-linear activation function and used to update the target node. In practice the functions <span class="math notranslate nohighlight">\(f\)</span> is approximated by a matrix (convolution) <span class="math notranslate nohighlight">\(Wk\)</span> with the added non-linearity of the activation function.</p>
<p>This entire process is visualized in the below diagram, taken from the excellent paper <a class="reference external" href="https://arxiv.org/abs/2010.05234">A Practical Guide to Graph Neural Networks</a></p>
<p><img alt="image.png" src="notebooks/attachment:image.png" /></p>
<section id="coding">
<h3>Coding!<a class="headerlink" href="#coding" title="Permalink to this heading">#</a></h3>
<section id="the-dataset">
<h4>The Dataset<a class="headerlink" href="#the-dataset" title="Permalink to this heading">#</a></h4>
<p>In this tutorial we will use the <a class="reference external" href="https://relational.fit.cvut.cz/dataset/CORA">Cora dataset</a> to predict the subject of a research paper given its words and citation network. The cora dataset consists of 2,708 scientific papers with a unique id classified into one of 7 classes. The citation network consists of 5,429 links. Each paper has an associated binary word vector of size 1,433 indiating the presence of correpsonding word fromt he pre-defined dictionary.</p>
<p>The dataset cnotains two tab-separateve files: <code class="docutils literal notranslate"><span class="pre">cora.cites</span></code> and <code class="docutils literal notranslate"><span class="pre">cora.content</span></code>. The cites file includes all pairs of citation records formulated as two columns: <code class="docutils literal notranslate"><span class="pre">cited_paper_id</span></code> (target) and <code class="docutils literal notranslate"><span class="pre">citing_paper_id</span></code> (source). The content file includes the paper content recors with 1,435 columns: <code class="docutils literal notranslate"><span class="pre">paper_id</span></code>, <code class="docutils literal notranslate"><span class="pre">subject</span></code> (training target), and 1,433 binary features corresponding to the binary word vector.</p>
<p>Let’s download the dataset</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># setup</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">Dropout</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.regularizers</span> <span class="kn">import</span> <span class="n">l2</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras.backend</span> <span class="k">as</span> <span class="nn">K</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (2.5.1)
Requirement already satisfied: decorator&lt;5,&gt;=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx) (4.4.2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># download the data</span>
<span class="n">zip_file</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">get_file</span><span class="p">(</span>
    <span class="n">fname</span><span class="o">=</span><span class="s2">&quot;cora.tgz&quot;</span><span class="p">,</span>
    <span class="n">origin</span><span class="o">=</span><span class="s2">&quot;https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz&quot;</span><span class="p">,</span>
    <span class="n">extract</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">data_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">zip_file</span><span class="p">),</span> <span class="s2">&quot;cora&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading data from https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz
172032/168052 [==============================] - 0s 0us/step
</pre></div>
</div>
</div>
</div>
<p>Load the cites data into a dataframe and get the shape. We expect it to be 5429x2, representing 5429 linked paper pairs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># load the cites data into a dataframe and get the shape (expect it to be 5429x2, representing 5429 linked paper pairs)</span>
<span class="n">citations</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s2">&quot;cora.cites&quot;</span><span class="p">),</span>
    <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">],</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Citations shape:&quot;</span><span class="p">,</span> <span class="n">citations</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Citations shape: (5429, 2)
</pre></div>
</div>
</div>
</div>
<p>We can also take a look at the beginning of the dataset</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">citations</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>target</th>
      <th>source</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>35</td>
      <td>1033</td>
    </tr>
    <tr>
      <th>1</th>
      <td>35</td>
      <td>103482</td>
    </tr>
    <tr>
      <th>2</th>
      <td>35</td>
      <td>103515</td>
    </tr>
    <tr>
      <th>3</th>
      <td>35</td>
      <td>1050679</td>
    </tr>
    <tr>
      <th>4</th>
      <td>35</td>
      <td>1103960</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The first few lines are listing the papers that reference paper ID 35.</p>
<p>Now we’ll load the papers data and get the shape and take a look at the first few entries. We expect this df to be 2708x1435: 2708 unique papers and their associated topic and word binaries.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">column_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;paper_id&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;term_</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1433</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;subject&quot;</span><span class="p">]</span>
<span class="n">papers</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s2">&quot;cora.content&quot;</span><span class="p">),</span>
    <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Papers shape:&quot;</span><span class="p">,</span> <span class="n">papers</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Papers shape: (2708, 1435)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">papers</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                 1412           178   ...             2084                2220
paper_id       120039        1153866  ...            51934               22229
term_0              0              0  ...                0                   0
term_1              0              0  ...                0                   0
term_2              0              0  ...                0                   0
term_3              0              0  ...                0                   0
...               ...            ...  ...              ...                 ...
term_1429           0              0  ...                0                   0
term_1430           0              0  ...                0                   0
term_1431           0              0  ...                0                   0
term_1432           0              0  ...                0                   0
subject    Case_Based  Rule_Learning  ...  Neural_Networks  Genetic_Algorithms

[1435 rows x 5 columns]
</pre></div>
</div>
</div>
</div>
<p>We can also look at the count of papers in each subject:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">papers</span><span class="o">.</span><span class="n">subject</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Neural_Networks           818
Probabilistic_Methods     426
Genetic_Algorithms        418
Theory                    351
Case_Based                298
Reinforcement_Learning    217
Rule_Learning             180
Name: subject, dtype: int64
</pre></div>
</div>
</div>
</div>
<p>We’ll do a bit of preprocessing to convert the paper ids and subjects into zero-based indices. The papers will be indexed starting from 0 and the paper subjects will be represented by a value between 0 and 7, correpsonding to the subject classes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">class_values</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">papers</span><span class="p">[</span><span class="s2">&quot;subject&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
<span class="n">class_idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="nb">id</span> <span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">class_values</span><span class="p">)}</span>
<span class="n">paper_idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">papers</span><span class="p">[</span><span class="s2">&quot;paper_id&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()))}</span>

<span class="n">papers</span><span class="p">[</span><span class="s2">&quot;paper_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">papers</span><span class="p">[</span><span class="s2">&quot;paper_id&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">name</span><span class="p">:</span> <span class="n">paper_idx</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
<span class="n">citations</span><span class="p">[</span><span class="s2">&quot;source&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">citations</span><span class="p">[</span><span class="s2">&quot;source&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">name</span><span class="p">:</span> <span class="n">paper_idx</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
<span class="n">citations</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">citations</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">name</span><span class="p">:</span> <span class="n">paper_idx</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
<span class="n">papers</span><span class="p">[</span><span class="s2">&quot;subject&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">papers</span><span class="p">[</span><span class="s2">&quot;subject&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">value</span><span class="p">:</span> <span class="n">class_idx</span><span class="p">[</span><span class="n">value</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>We can use the <code class="docutils literal notranslate"><span class="pre">networkx</span></code> package to visualize a subset of the papers in the citation graph format. Each node will represent an idividual paper, nodes will be connected by an edge if one paper cites the other, and the color of each node will represent subject area.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">colors</span> <span class="o">=</span> <span class="n">papers</span><span class="p">[</span><span class="s2">&quot;subject&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">cora_graph</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_pandas_edgelist</span><span class="p">(</span><span class="n">citations</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">1500</span><span class="p">))</span>
<span class="n">subjects</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">papers</span><span class="p">[</span><span class="n">papers</span><span class="p">[</span><span class="s2">&quot;paper_id&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">cora_graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">))][</span><span class="s2">&quot;subject&quot;</span><span class="p">])</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_spring</span><span class="p">(</span><span class="n">cora_graph</span><span class="p">,</span> <span class="n">node_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="n">subjects</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/b59844779506749d7159e781bd4d97b8329968017206df6fe2f68e4190468627.png" src="../_images/b59844779506749d7159e781bd4d97b8329968017206df6fe2f68e4190468627.png" />
</div>
</div>
<p>Finally, we’ll split the data into train and test sets</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">group_data</span> <span class="ow">in</span> <span class="n">papers</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;subject&quot;</span><span class="p">):</span>
    <span class="c1"># Select around 50% of the dataset for training.</span>
    <span class="n">random_selection</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">group_data</span><span class="o">.</span><span class="n">index</span><span class="p">))</span> <span class="o">&lt;=</span> <span class="mf">0.5</span>
    <span class="n">train_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">group_data</span><span class="p">[</span><span class="n">random_selection</span><span class="p">])</span>
    <span class="n">test_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">group_data</span><span class="p">[</span><span class="o">~</span><span class="n">random_selection</span><span class="p">])</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train data shape:&quot;</span><span class="p">,</span> <span class="n">train_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test data shape:&quot;</span><span class="p">,</span> <span class="n">test_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train data shape: (1361, 1435)
Test data shape: (1347, 1435)
</pre></div>
</div>
</div>
</div>
</section>
<section id="experiment-setup">
<h4>Experiment setup<a class="headerlink" href="#experiment-setup" title="Permalink to this heading">#</a></h4>
<p>We’ll define a few helper functions to use as we develop and train our GNN. Let’s start with setting some hyperparameters:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hidden_units</span> <span class="o">=</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">]</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">dropout_rate</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">256</span>
</pre></div>
</div>
</div>
</div>
<p>Define a function to compile and train a selected model using the training data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">run_experiment</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">):</span>
    <span class="c1"># Compile the model.</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">),</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;acc&quot;</span><span class="p">)],</span>
    <span class="p">)</span>
    <span class="c1"># Create an early stopping callback.</span>
    <span class="n">early_stopping</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span>
        <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_acc&quot;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">restore_best_weights</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    <span class="c1"># Fit the model.</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x_train</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">early_stopping</span><span class="p">],</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">history</span>
</pre></div>
</div>
</div>
</div>
<p>And one to display the training loss and accuracy curves:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">display_learning_curves</span><span class="p">(</span><span class="n">history</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">])</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">])</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper right&quot;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>

    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;acc&quot;</span><span class="p">])</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_acc&quot;</span><span class="p">])</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper right&quot;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>And one to construct a simple Feed-Forward Network (FFN)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_ffn</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">fnn_layers</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">units</span> <span class="ow">in</span> <span class="n">hidden_units</span><span class="p">:</span>
        <span class="n">fnn_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">())</span>
        <span class="n">fnn_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))</span>
        <span class="n">fnn_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">fnn_layers</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="converting-data-to-a-graph">
<h4>Converting data to a graph<a class="headerlink" href="#converting-data-to-a-graph" title="Permalink to this heading">#</a></h4>
<p>In order to use the Cora dataset with a GNN we need to transform it into the format expected by Keras. This is often one of the most challenging parts of building a GNN model as each library has slightly different expected data formats and different systems have varying memory constraints. Here we will demonstrate a simple approach for preparing and using graph data if your dataset contains only a signle graph that fits entirely in memory.</p>
<p>In Keras, the graph data is represented by a <code class="docutils literal notranslate"><span class="pre">graph_info</span></code> tuple which consists of three elements:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">node_features</span></code>: This is a <code class="docutils literal notranslate"><span class="pre">[num_nodes,</span> <span class="pre">num_features]</span></code> Numpy array that includes the features of each node. In our case each node is a paper and the features are the word presence binary vectors.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">edges</span></code>: This is a <code class="docutils literal notranslate"><span class="pre">[2,num_edges]</span></code> Numpy arrary representing a sparce adjacency matrix of the links between the nodes. For each edge this array includes the node index of the source and target node. In our case, these are the citing paper and cited paper IDs.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">edge_weights</span></code> (optional): This is a <code class="docutils literal notranslate"><span class="pre">[num_edges]</span></code> Numpy array that includes the edge weights which quantify the relationship between the nodes. In our exaple we don’t use edge weights, but a possible example of a useful edge weight for this task could be the impact factor of the journal where the citing paper is published.</p></li>
</ol>
<p>We’ll also define an array <code class="docutils literal notranslate"><span class="pre">y</span></code> containing the subject labels for each paper ID.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">feature_names</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">papers</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span> <span class="o">-</span> <span class="p">{</span><span class="s2">&quot;paper_id&quot;</span><span class="p">,</span> <span class="s2">&quot;subject&quot;</span><span class="p">}</span>
<span class="n">num_features</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">class_idx</span><span class="p">)</span>
<span class="c1"># Create train and test features as a numpy array.</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="n">feature_names</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">feature_names</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="s2">&quot;subject&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="s2">&quot;subject&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1925    1
2345    6
2607    0
2271    1
1123    0
       ..
701     2
1699    0
1491    6
666     2
906     2
Name: subject, Length: 1361, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create an edges array (sparse adjacency matrix) of shape [2, num_edges].</span>
<span class="n">edges</span> <span class="o">=</span> <span class="n">citations</span><span class="p">[[</span><span class="s2">&quot;source&quot;</span><span class="p">,</span> <span class="s2">&quot;target&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">T</span>
<span class="c1"># Create an edge weights array of ones.</span>
<span class="n">edge_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">edges</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="c1"># Create a node features array of shape [num_nodes, num_features].</span>
<span class="n">node_features</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
    <span class="n">papers</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;paper_id&quot;</span><span class="p">)[</span><span class="n">feature_names</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">float32</span>
<span class="p">)</span>
<span class="c1"># Create graph info tuple with node_features, edges, and edge_weights.</span>
<span class="n">graph_info</span> <span class="o">=</span> <span class="p">(</span><span class="n">node_features</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="n">edge_weights</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Edges shape:&quot;</span><span class="p">,</span> <span class="n">edges</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Nodes shape:&quot;</span><span class="p">,</span> <span class="n">node_features</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Edges shape: (2, 5429)
Nodes shape: (2708, 1433)
</pre></div>
</div>
</div>
</div>
</section>
<section id="build-the-model">
<h4>Build the model!<a class="headerlink" href="#build-the-model" title="Permalink to this heading">#</a></h4>
<p>We’ll start by defining a graph convolution layer. It performs the following steps:</p>
<ol class="arabic simple">
<li><p><strong>Prepare</strong>: The input node representations are processed using a Feed-Forward Network (FFN) to produce a message. You can simplify the processing by only applying linear transformation to the representations.</p></li>
<li><p><strong>Aggregate</strong>: The messages of the neighbours of each node are aggregated with respect to the edge_weights using a permutation invariant pooling operation, such as sum, mean, or max, to prepare a single aggregated message for each node. See, for example, tf.math.unsorted_segment_sum APIs used to aggregate neighbour messages.</p></li>
<li><p><strong>Update</strong>: The node_repesentations and aggregated_messages—both of shape <code class="docutils literal notranslate"><span class="pre">[num_nodes,</span> <span class="pre">representation_dim]</span></code> — are combined and processed to produce the new state of the node representations (node embeddings). If combination_type is gru, the node_repesentations and aggregated_messages are stacked to create a sequence, then processed by a GRU layer. Otherwise, the node_repesentations and aggregated_messages are added or concatenated, then processed using a FFN.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Graph convolutional layer</span>


<span class="k">class</span> <span class="nc">GraphConvLayer</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">hidden_units</span><span class="p">,</span>
        <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
        <span class="n">aggregation_type</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
        <span class="n">combination_type</span><span class="o">=</span><span class="s2">&quot;concat&quot;</span><span class="p">,</span>
        <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GraphConvLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">aggregation_type</span> <span class="o">=</span> <span class="n">aggregation_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">combination_type</span> <span class="o">=</span> <span class="n">combination_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="n">normalize</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">ffn_prepare</span> <span class="o">=</span> <span class="n">create_ffn</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">combination_type</span> <span class="o">==</span> <span class="s2">&quot;gated&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_fn</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span>
                <span class="n">units</span><span class="o">=</span><span class="n">hidden_units</span><span class="p">,</span>
                <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;tanh&quot;</span><span class="p">,</span>
                <span class="n">recurrent_activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">,</span>
                <span class="n">dropout</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span>
                <span class="n">return_state</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">recurrent_dropout</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_fn</span> <span class="o">=</span> <span class="n">create_ffn</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">prepare</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_repesentations</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># node_repesentations shape is [num_edges, embedding_dim].</span>
        <span class="n">messages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn_prepare</span><span class="p">(</span><span class="n">node_repesentations</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">messages</span> <span class="o">=</span> <span class="n">messages</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">messages</span>

    <span class="k">def</span> <span class="nf">aggregate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_indices</span><span class="p">,</span> <span class="n">neighbour_messages</span><span class="p">):</span>
        <span class="c1"># node_indices shape is [num_edges].</span>
        <span class="c1"># neighbour_messages shape: [num_edges, representation_dim].</span>
        <span class="n">num_nodes</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">node_indices</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregation_type</span> <span class="o">==</span> <span class="s2">&quot;sum&quot;</span><span class="p">:</span>
            <span class="n">aggregated_message</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">unsorted_segment_sum</span><span class="p">(</span>
                <span class="n">neighbour_messages</span><span class="p">,</span> <span class="n">node_indices</span><span class="p">,</span> <span class="n">num_segments</span><span class="o">=</span><span class="n">num_nodes</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregation_type</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
            <span class="n">aggregated_message</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">unsorted_segment_mean</span><span class="p">(</span>
                <span class="n">neighbour_messages</span><span class="p">,</span> <span class="n">node_indices</span><span class="p">,</span> <span class="n">num_segments</span><span class="o">=</span><span class="n">num_nodes</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregation_type</span> <span class="o">==</span> <span class="s2">&quot;max&quot;</span><span class="p">:</span>
            <span class="n">aggregated_message</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">unsorted_segment_max</span><span class="p">(</span>
                <span class="n">neighbour_messages</span><span class="p">,</span> <span class="n">node_indices</span><span class="p">,</span> <span class="n">num_segments</span><span class="o">=</span><span class="n">num_nodes</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid aggregation type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">aggregation_type</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">aggregated_message</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_repesentations</span><span class="p">,</span> <span class="n">aggregated_messages</span><span class="p">):</span>
        <span class="c1"># node_repesentations shape is [num_nodes, representation_dim].</span>
        <span class="c1"># aggregated_messages shape is [num_nodes, representation_dim].</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">combination_type</span> <span class="o">==</span> <span class="s2">&quot;gru&quot;</span><span class="p">:</span>
            <span class="c1"># Create a sequence of two elements for the GRU layer.</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">node_repesentations</span><span class="p">,</span> <span class="n">aggregated_messages</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">combination_type</span> <span class="o">==</span> <span class="s2">&quot;concat&quot;</span><span class="p">:</span>
            <span class="c1"># Concatenate the node_repesentations and aggregated_messages.</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">node_repesentations</span><span class="p">,</span> <span class="n">aggregated_messages</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">combination_type</span> <span class="o">==</span> <span class="s2">&quot;add&quot;</span><span class="p">:</span>
            <span class="c1"># Add node_repesentations and aggregated_messages.</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">node_repesentations</span> <span class="o">+</span> <span class="n">aggregated_messages</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid combination type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">combination_type</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

        <span class="c1"># Apply the processing function.</span>
        <span class="n">node_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_fn</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">combination_type</span> <span class="o">==</span> <span class="s2">&quot;gru&quot;</span><span class="p">:</span>
            <span class="n">node_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">node_embeddings</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">:</span>
            <span class="n">node_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">l2_normalize</span><span class="p">(</span><span class="n">node_embeddings</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">node_embeddings</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Process the inputs to produce the node_embeddings.</span>

<span class="sd">        inputs: a tuple of three elements: node_repesentations, edges, edge_weights.</span>
<span class="sd">        Returns: node_embeddings of shape [num_nodes, representation_dim].</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">node_repesentations</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="n">edge_weights</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="c1"># Get node_indices (source) and neighbour_indices (target) from edges.</span>
        <span class="n">node_indices</span><span class="p">,</span> <span class="n">neighbour_indices</span> <span class="o">=</span> <span class="n">edges</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">edges</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># neighbour_repesentations shape is [num_edges, representation_dim].</span>
        <span class="n">neighbour_repesentations</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">node_repesentations</span><span class="p">,</span> <span class="n">neighbour_indices</span><span class="p">)</span>

        <span class="c1"># Prepare the messages of the neighbours.</span>
        <span class="n">neighbour_messages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">neighbour_repesentations</span><span class="p">,</span> <span class="n">edge_weights</span><span class="p">)</span>
        <span class="c1"># Aggregate the neighbour messages.</span>
        <span class="n">aggregated_messages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregate</span><span class="p">(</span><span class="n">node_indices</span><span class="p">,</span> <span class="n">neighbour_messages</span><span class="p">)</span>
        <span class="c1"># Update the node embedding with the neighbour messages.</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">node_repesentations</span><span class="p">,</span> <span class="n">aggregated_messages</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now we can use this GCN layer in a full GNN architecture for node classification. We’ll define our network as follows:</p>
<ol class="arabic simple">
<li><p>Apply preprocessing using FFN to the node features to generate initial node representations. (This step is optional as you can just use the original node features as the initial representation).</p></li>
<li><p>Apply one or more graph convolutional layer, with skip connections, to the node representation to produce node embeddings.</p></li>
<li><p>Apply post-processing using FFN to the node embeddings to generat the final node embeddings.</p></li>
<li><p>Feed the node embeddings in a Softmax layer to predict the node class.</p></li>
</ol>
<p>Each graph convolutional layer added captures information from a further level of neighbours. However, adding many graph convolutional layer can cause oversmoothing, where the model produces similar embeddings for all the nodes. The number of message passing iterations can be considered a tuneable hyperparameter.</p>
<p>Note that the graph_info passed to the constructor of the Keras model, and used as a property of the Keras model object, rather than input data for training or prediction. The model will accept a batch of node_indices, which are used to lookup the node features and neighbours from the graph_info.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GNNNodeClassifier</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">graph_info</span><span class="p">,</span>
        <span class="n">num_classes</span><span class="p">,</span>
        <span class="n">hidden_units</span><span class="p">,</span>
        <span class="n">aggregation_type</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">,</span>
        <span class="n">combination_type</span><span class="o">=</span><span class="s2">&quot;concat&quot;</span><span class="p">,</span>
        <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
        <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GNNNodeClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Unpack graph_info to three elements: node_features, edges, and edge_weight.</span>
        <span class="n">node_features</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="n">edge_weights</span> <span class="o">=</span> <span class="n">graph_info</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">node_features</span> <span class="o">=</span> <span class="n">node_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">edges</span> <span class="o">=</span> <span class="n">edges</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">edge_weights</span> <span class="o">=</span> <span class="n">edge_weights</span>
        <span class="c1"># Set edge_weights to ones if not provided.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">edge_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">edges</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="c1"># Scale edge_weights to sum to 1.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">edge_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_weights</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_weights</span><span class="p">)</span>

        <span class="c1"># Create a process layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span> <span class="o">=</span> <span class="n">create_ffn</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;preprocess&quot;</span><span class="p">)</span>
        <span class="c1"># Create the first GraphConv layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">GraphConvLayer</span><span class="p">(</span>
            <span class="n">hidden_units</span><span class="p">,</span>
            <span class="n">dropout_rate</span><span class="p">,</span>
            <span class="n">aggregation_type</span><span class="p">,</span>
            <span class="n">combination_type</span><span class="p">,</span>
            <span class="n">normalize</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;graph_conv1&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Create the second GraphConv layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">GraphConvLayer</span><span class="p">(</span>
            <span class="n">hidden_units</span><span class="p">,</span>
            <span class="n">dropout_rate</span><span class="p">,</span>
            <span class="n">aggregation_type</span><span class="p">,</span>
            <span class="n">combination_type</span><span class="p">,</span>
            <span class="n">normalize</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;graph_conv2&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Create a postprocess layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">postprocess</span> <span class="o">=</span> <span class="n">create_ffn</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;postprocess&quot;</span><span class="p">)</span>
        <span class="c1"># Create a compute logits layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compute_logits</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;logits&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_node_indices</span><span class="p">):</span>
        <span class="c1"># Preprocess the node_features to produce node representations.</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_features</span><span class="p">)</span>
        <span class="c1"># Apply the first graph conv layer.</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">edges</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_weights</span><span class="p">))</span>
        <span class="c1"># Skip connection.</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x1</span> <span class="o">+</span> <span class="n">x</span>
        <span class="c1"># Apply the second graph conv layer.</span>
        <span class="n">x2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">edges</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_weights</span><span class="p">))</span>
        <span class="c1"># Skip connection.</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x2</span> <span class="o">+</span> <span class="n">x</span>
        <span class="c1"># Postprocess node embedding.</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocess</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Fetch node embeddings for the input node_indices.</span>
        <span class="n">node_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">input_node_indices</span><span class="p">))</span>
        <span class="c1"># Compute logits</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_logits</span><span class="p">(</span><span class="n">node_embeddings</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s try calling our model!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gnn_model</span> <span class="o">=</span> <span class="n">GNNNodeClassifier</span><span class="p">(</span>
    <span class="n">graph_info</span><span class="o">=</span><span class="n">graph_info</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
    <span class="n">hidden_units</span><span class="o">=</span><span class="n">hidden_units</span><span class="p">,</span>
    <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;gnn_model&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GNN output shape:&quot;</span><span class="p">,</span> <span class="n">gnn_model</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]))</span>

<span class="n">gnn_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GNN output shape: tf.Tensor(
[[ 1.8012416e-02  4.9491808e-02  9.8944223e-03  1.1198113e-01
   7.6205209e-02 -1.4386458e-04  2.3376463e-02]
 [ 7.1263225e-03  7.7160872e-03  4.3582007e-02  9.7338274e-02
   1.0342301e-01  4.5803756e-02  1.4947498e-01]
 [-1.0139931e-01 -2.6689304e-02 -1.2470722e-02  6.9937572e-02
   1.9118384e-03 -4.9269162e-02  1.7952232e-01]], shape=(3, 7), dtype=float32)
Model: &quot;gnn_model&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
preprocess (Sequential)      (2708, 32)                52804     
_________________________________________________________________
graph_conv1 (GraphConvLayer) multiple                  5888      
_________________________________________________________________
graph_conv2 (GraphConvLayer) multiple                  5888      
_________________________________________________________________
postprocess (Sequential)     (2708, 32)                2368      
_________________________________________________________________
logits (Dense)               multiple                  231       
=================================================================
Total params: 67,179
Trainable params: 63,481
Non-trainable params: 3,698
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
</section>
<section id="train-the-model">
<h4>Train the model<a class="headerlink" href="#train-the-model" title="Permalink to this heading">#</a></h4>
<p>We’re ready to train our GNN! We’ll use standard supervised cross-entropy loss to train the model as defined in our helper function above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_train</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">paper_id</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">run_experiment</span><span class="p">(</span><span class="n">gnn_model</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/300
WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.
Instructions for updating:
The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.
5/5 [==============================] - 8s 247ms/step - loss: 2.2244 - acc: 0.1652 - val_loss: 1.9001 - val_acc: 0.2732
Epoch 2/300
5/5 [==============================] - 1s 140ms/step - loss: 1.9735 - acc: 0.2552 - val_loss: 1.8958 - val_acc: 0.2585
Epoch 3/300
5/5 [==============================] - 1s 145ms/step - loss: 1.9356 - acc: 0.2517 - val_loss: 1.9035 - val_acc: 0.1756
Epoch 4/300
5/5 [==============================] - 1s 145ms/step - loss: 1.8796 - acc: 0.2448 - val_loss: 1.9045 - val_acc: 0.2000
Epoch 5/300
5/5 [==============================] - 1s 140ms/step - loss: 1.8755 - acc: 0.2561 - val_loss: 1.8984 - val_acc: 0.2732
Epoch 6/300
5/5 [==============================] - 1s 144ms/step - loss: 1.8457 - acc: 0.2751 - val_loss: 1.8910 - val_acc: 0.2878
Epoch 7/300
5/5 [==============================] - 1s 145ms/step - loss: 1.8179 - acc: 0.2863 - val_loss: 1.8879 - val_acc: 0.2927
Epoch 8/300
5/5 [==============================] - 1s 141ms/step - loss: 1.8354 - acc: 0.3010 - val_loss: 1.8893 - val_acc: 0.2976
Epoch 9/300
5/5 [==============================] - 1s 143ms/step - loss: 1.8101 - acc: 0.2933 - val_loss: 1.8938 - val_acc: 0.3220
Epoch 10/300
5/5 [==============================] - 1s 145ms/step - loss: 1.8135 - acc: 0.2993 - val_loss: 1.8948 - val_acc: 0.3415
Epoch 11/300
5/5 [==============================] - 1s 145ms/step - loss: 1.8003 - acc: 0.2855 - val_loss: 1.8898 - val_acc: 0.3317
Epoch 12/300
5/5 [==============================] - 1s 140ms/step - loss: 1.7554 - acc: 0.3123 - val_loss: 1.8762 - val_acc: 0.3317
Epoch 13/300
5/5 [==============================] - 1s 145ms/step - loss: 1.7170 - acc: 0.3157 - val_loss: 1.8678 - val_acc: 0.2976
Epoch 14/300
5/5 [==============================] - 1s 143ms/step - loss: 1.7045 - acc: 0.3408 - val_loss: 1.8300 - val_acc: 0.3171
Epoch 15/300
5/5 [==============================] - 1s 144ms/step - loss: 1.6428 - acc: 0.3529 - val_loss: 1.7600 - val_acc: 0.3415
Epoch 16/300
5/5 [==============================] - 1s 145ms/step - loss: 1.6111 - acc: 0.3711 - val_loss: 1.7168 - val_acc: 0.3512
Epoch 17/300
5/5 [==============================] - 1s 143ms/step - loss: 1.5963 - acc: 0.3685 - val_loss: 1.6897 - val_acc: 0.3610
Epoch 18/300
5/5 [==============================] - 1s 143ms/step - loss: 1.5500 - acc: 0.3936 - val_loss: 1.6892 - val_acc: 0.3610
Epoch 19/300
5/5 [==============================] - 1s 144ms/step - loss: 1.4903 - acc: 0.4308 - val_loss: 1.6075 - val_acc: 0.3756
Epoch 20/300
5/5 [==============================] - 1s 141ms/step - loss: 1.4711 - acc: 0.4265 - val_loss: 1.4972 - val_acc: 0.4146
Epoch 21/300
5/5 [==============================] - 1s 144ms/step - loss: 1.4419 - acc: 0.4420 - val_loss: 1.4001 - val_acc: 0.4683
Epoch 22/300
5/5 [==============================] - 1s 141ms/step - loss: 1.4485 - acc: 0.4187 - val_loss: 1.3620 - val_acc: 0.4732
Epoch 23/300
5/5 [==============================] - 1s 140ms/step - loss: 1.4175 - acc: 0.4637 - val_loss: 1.3348 - val_acc: 0.5024
Epoch 24/300
5/5 [==============================] - 1s 141ms/step - loss: 1.3628 - acc: 0.4766 - val_loss: 1.3398 - val_acc: 0.4976
Epoch 25/300
5/5 [==============================] - 1s 141ms/step - loss: 1.3144 - acc: 0.5009 - val_loss: 1.2970 - val_acc: 0.5122
Epoch 26/300
5/5 [==============================] - 1s 140ms/step - loss: 1.3077 - acc: 0.4922 - val_loss: 1.3101 - val_acc: 0.5073
Epoch 27/300
5/5 [==============================] - 1s 143ms/step - loss: 1.2317 - acc: 0.5329 - val_loss: 1.3433 - val_acc: 0.4732
Epoch 28/300
5/5 [==============================] - 1s 143ms/step - loss: 1.2504 - acc: 0.5311 - val_loss: 1.2852 - val_acc: 0.4780
Epoch 29/300
5/5 [==============================] - 1s 140ms/step - loss: 1.1998 - acc: 0.5493 - val_loss: 1.2063 - val_acc: 0.5122
Epoch 30/300
5/5 [==============================] - 1s 145ms/step - loss: 1.1639 - acc: 0.5718 - val_loss: 1.1976 - val_acc: 0.5366
Epoch 31/300
5/5 [==============================] - 1s 140ms/step - loss: 1.1568 - acc: 0.5770 - val_loss: 1.1823 - val_acc: 0.5317
Epoch 32/300
5/5 [==============================] - 1s 140ms/step - loss: 1.1354 - acc: 0.5839 - val_loss: 1.1684 - val_acc: 0.5366
Epoch 33/300
5/5 [==============================] - 1s 143ms/step - loss: 1.1260 - acc: 0.6021 - val_loss: 1.2831 - val_acc: 0.5220
Epoch 34/300
5/5 [==============================] - 1s 143ms/step - loss: 1.0331 - acc: 0.6349 - val_loss: 1.4262 - val_acc: 0.4732
Epoch 35/300
5/5 [==============================] - 1s 139ms/step - loss: 1.0573 - acc: 0.6289 - val_loss: 1.2684 - val_acc: 0.5024
Epoch 36/300
5/5 [==============================] - 1s 142ms/step - loss: 1.0007 - acc: 0.6427 - val_loss: 1.2165 - val_acc: 0.5317
Epoch 37/300
5/5 [==============================] - 1s 143ms/step - loss: 0.9985 - acc: 0.6453 - val_loss: 1.0860 - val_acc: 0.5805
Epoch 38/300
5/5 [==============================] - 1s 142ms/step - loss: 0.9580 - acc: 0.6574 - val_loss: 1.0294 - val_acc: 0.6195
Epoch 39/300
5/5 [==============================] - 1s 141ms/step - loss: 0.9429 - acc: 0.6808 - val_loss: 0.9950 - val_acc: 0.6537
Epoch 40/300
5/5 [==============================] - 1s 144ms/step - loss: 0.9105 - acc: 0.6869 - val_loss: 1.0127 - val_acc: 0.6488
Epoch 41/300
5/5 [==============================] - 1s 141ms/step - loss: 0.9006 - acc: 0.6860 - val_loss: 0.9464 - val_acc: 0.6537
Epoch 42/300
5/5 [==============================] - 1s 141ms/step - loss: 0.9285 - acc: 0.6652 - val_loss: 0.9336 - val_acc: 0.6829
Epoch 43/300
5/5 [==============================] - 1s 141ms/step - loss: 0.8650 - acc: 0.7042 - val_loss: 0.9341 - val_acc: 0.6829
Epoch 44/300
5/5 [==============================] - 1s 141ms/step - loss: 0.8885 - acc: 0.6929 - val_loss: 0.9109 - val_acc: 0.6927
Epoch 45/300
5/5 [==============================] - 1s 139ms/step - loss: 0.8801 - acc: 0.6808 - val_loss: 0.9135 - val_acc: 0.6780
Epoch 46/300
5/5 [==============================] - 1s 144ms/step - loss: 0.8368 - acc: 0.7050 - val_loss: 0.8939 - val_acc: 0.6780
Epoch 47/300
5/5 [==============================] - 1s 142ms/step - loss: 0.8905 - acc: 0.6903 - val_loss: 0.9411 - val_acc: 0.6488
Epoch 48/300
5/5 [==============================] - 1s 142ms/step - loss: 0.8127 - acc: 0.7154 - val_loss: 1.0425 - val_acc: 0.6293
Epoch 49/300
5/5 [==============================] - 1s 146ms/step - loss: 0.8143 - acc: 0.7119 - val_loss: 1.1930 - val_acc: 0.5561
Epoch 50/300
5/5 [==============================] - 1s 140ms/step - loss: 0.8186 - acc: 0.7145 - val_loss: 1.1099 - val_acc: 0.5902
Epoch 51/300
5/5 [==============================] - 1s 142ms/step - loss: 0.7810 - acc: 0.7318 - val_loss: 1.1912 - val_acc: 0.5707
Epoch 52/300
5/5 [==============================] - 1s 143ms/step - loss: 0.7811 - acc: 0.7240 - val_loss: 1.1918 - val_acc: 0.5854
Epoch 53/300
5/5 [==============================] - 1s 141ms/step - loss: 0.7828 - acc: 0.7318 - val_loss: 0.9551 - val_acc: 0.6488
Epoch 54/300
5/5 [==============================] - 1s 141ms/step - loss: 0.7289 - acc: 0.7362 - val_loss: 0.8898 - val_acc: 0.6927
Epoch 55/300
5/5 [==============================] - 1s 146ms/step - loss: 0.7325 - acc: 0.7465 - val_loss: 0.8689 - val_acc: 0.6829
Epoch 56/300
5/5 [==============================] - 1s 139ms/step - loss: 0.7387 - acc: 0.7465 - val_loss: 0.8667 - val_acc: 0.6732
Epoch 57/300
5/5 [==============================] - 1s 140ms/step - loss: 0.7639 - acc: 0.7448 - val_loss: 0.8550 - val_acc: 0.6927
Epoch 58/300
5/5 [==============================] - 1s 141ms/step - loss: 0.7373 - acc: 0.7448 - val_loss: 0.8437 - val_acc: 0.6829
Epoch 59/300
5/5 [==============================] - 1s 147ms/step - loss: 0.7542 - acc: 0.7396 - val_loss: 0.8669 - val_acc: 0.6927
Epoch 60/300
5/5 [==============================] - 1s 145ms/step - loss: 0.7198 - acc: 0.7517 - val_loss: 0.8873 - val_acc: 0.6732
Epoch 61/300
5/5 [==============================] - 1s 138ms/step - loss: 0.6944 - acc: 0.7604 - val_loss: 0.8909 - val_acc: 0.6829
Epoch 62/300
5/5 [==============================] - 1s 142ms/step - loss: 0.7004 - acc: 0.7552 - val_loss: 0.8654 - val_acc: 0.7024
Epoch 63/300
5/5 [==============================] - 1s 140ms/step - loss: 0.6490 - acc: 0.7881 - val_loss: 0.8734 - val_acc: 0.7122
Epoch 64/300
2/5 [===========&gt;..................] - ETA: 0s - loss: 0.7780 - acc: 0.7539
</pre></div>
</div>
</div>
</div>
<p>Let’s plot the learning curves</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display_learning_curves</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And finally we can evaluate the GNN on the test data split!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_test</span> <span class="o">=</span> <span class="n">test_data</span><span class="o">.</span><span class="n">paper_id</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">_</span><span class="p">,</span> <span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">gnn_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test accuracy: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">test_accuracy</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="3-conv2d.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Convolutional Neural Networks for Jet-Images</p>
      </div>
    </a>
    <a class="right-next"
       href="5-vae-mnist.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Variational Autoencoders with Keras and MNIST</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#coding">Coding!</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-dataset">The Dataset</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#experiment-setup">Experiment setup</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#converting-data-to-a-graph">Converting data to a graph</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#build-the-model">Build the model!</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#train-the-model">Train the model</a></li>
</ul>
</li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Raghav Kansal, on behalf of the LPC
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>